{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-12T17:46:00.672101Z",
     "iopub.status.busy": "2025-03-12T17:46:00.671840Z",
     "iopub.status.idle": "2025-03-12T17:46:02.884092Z",
     "shell.execute_reply": "2025-03-12T17:46:02.883214Z",
     "shell.execute_reply.started": "2025-03-12T17:46:00.672072Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\cifar-10-batches-py\\batches.meta\n",
      "data\\cifar-10-batches-py\\data_batch_1\n",
      "data\\cifar-10-batches-py\\data_batch_2\n",
      "data\\cifar-10-batches-py\\data_batch_3\n",
      "data\\cifar-10-batches-py\\data_batch_4\n",
      "data\\cifar-10-batches-py\\data_batch_5\n",
      "data\\cifar-10-batches-py\\readme.html\n",
      "data\\cifar-10-batches-py\\test_batch\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data\\cifar-10-batches-py'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T18:46:05.051377Z",
     "iopub.status.busy": "2025-03-12T18:46:05.051025Z",
     "iopub.status.idle": "2025-03-12T19:36:11.794399Z",
     "shell.execute_reply": "2025-03-12T19:36:11.793529Z",
     "shell.execute_reply.started": "2025-03-12T18:46:05.051341Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "            Conv2d-7           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-8           [-1, 64, 32, 32]             128\n",
      "              ReLU-9           [-1, 64, 32, 32]               0\n",
      "    ResidualBlock-10           [-1, 64, 32, 32]               0\n",
      "           Conv2d-11           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-12           [-1, 64, 32, 32]             128\n",
      "             ReLU-13           [-1, 64, 32, 32]               0\n",
      "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 32, 32]             128\n",
      "             ReLU-16           [-1, 64, 32, 32]               0\n",
      "    ResidualBlock-17           [-1, 64, 32, 32]               0\n",
      "           Conv2d-18           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-19           [-1, 64, 32, 32]             128\n",
      "             ReLU-20           [-1, 64, 32, 32]               0\n",
      "           Conv2d-21           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 32, 32]             128\n",
      "             ReLU-23           [-1, 64, 32, 32]               0\n",
      "    ResidualBlock-24           [-1, 64, 32, 32]               0\n",
      "           Conv2d-25           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-26           [-1, 64, 32, 32]             128\n",
      "             ReLU-27           [-1, 64, 32, 32]               0\n",
      "           Conv2d-28           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-29           [-1, 64, 32, 32]             128\n",
      "             ReLU-30           [-1, 64, 32, 32]               0\n",
      "    ResidualBlock-31           [-1, 64, 32, 32]               0\n",
      "           Conv2d-32          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-33          [-1, 128, 16, 16]             256\n",
      "           Conv2d-34          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-35          [-1, 128, 16, 16]             256\n",
      "             ReLU-36          [-1, 128, 16, 16]               0\n",
      "           Conv2d-37          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-38          [-1, 128, 16, 16]             256\n",
      "             ReLU-39          [-1, 128, 16, 16]               0\n",
      "    ResidualBlock-40          [-1, 128, 16, 16]               0\n",
      "           Conv2d-41          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-42          [-1, 128, 16, 16]             256\n",
      "             ReLU-43          [-1, 128, 16, 16]               0\n",
      "           Conv2d-44          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-45          [-1, 128, 16, 16]             256\n",
      "             ReLU-46          [-1, 128, 16, 16]               0\n",
      "    ResidualBlock-47          [-1, 128, 16, 16]               0\n",
      "           Conv2d-48          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-49          [-1, 128, 16, 16]             256\n",
      "             ReLU-50          [-1, 128, 16, 16]               0\n",
      "           Conv2d-51          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-52          [-1, 128, 16, 16]             256\n",
      "             ReLU-53          [-1, 128, 16, 16]               0\n",
      "    ResidualBlock-54          [-1, 128, 16, 16]               0\n",
      "           Conv2d-55          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-56          [-1, 128, 16, 16]             256\n",
      "             ReLU-57          [-1, 128, 16, 16]               0\n",
      "           Conv2d-58          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-59          [-1, 128, 16, 16]             256\n",
      "             ReLU-60          [-1, 128, 16, 16]               0\n",
      "    ResidualBlock-61          [-1, 128, 16, 16]               0\n",
      "           Conv2d-62            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-63            [-1, 256, 8, 8]             512\n",
      "           Conv2d-64            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-65            [-1, 256, 8, 8]             512\n",
      "             ReLU-66            [-1, 256, 8, 8]               0\n",
      "           Conv2d-67            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-68            [-1, 256, 8, 8]             512\n",
      "             ReLU-69            [-1, 256, 8, 8]               0\n",
      "    ResidualBlock-70            [-1, 256, 8, 8]               0\n",
      "           Conv2d-71            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-72            [-1, 256, 8, 8]             512\n",
      "             ReLU-73            [-1, 256, 8, 8]               0\n",
      "           Conv2d-74            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-75            [-1, 256, 8, 8]             512\n",
      "             ReLU-76            [-1, 256, 8, 8]               0\n",
      "    ResidualBlock-77            [-1, 256, 8, 8]               0\n",
      "           Conv2d-78            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-79            [-1, 256, 8, 8]             512\n",
      "             ReLU-80            [-1, 256, 8, 8]               0\n",
      "           Conv2d-81            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-82            [-1, 256, 8, 8]             512\n",
      "             ReLU-83            [-1, 256, 8, 8]               0\n",
      "    ResidualBlock-84            [-1, 256, 8, 8]               0\n",
      "AdaptiveAvgPool2d-85            [-1, 256, 1, 1]               0\n",
      "           Linear-86                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 4,697,162\n",
      "Trainable params: 4,697,162\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 25.88\n",
      "Params size (MB): 17.92\n",
      "Estimated Total Size (MB): 43.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "from PIL import Image\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# auto. choose CPU or GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Function to load CIFAR-10 dataset\n",
    "def load_cifar_batch(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Specify the directory containing CIFAR-10 batches\n",
    "cifar10_dir = 'data\\cifar-10-batches-py'\n",
    "# Load metadata (labels)\n",
    "meta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\n",
    "label_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n",
    "\n",
    "# Load training data\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for i in range(1, 6):\n",
    "    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n",
    "    train_data.append(batch[b'data'])\n",
    "    train_labels += batch[b'labels']\n",
    "\n",
    "train_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness = 0.1,contrast = 0.1,saturation = 0.1),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor = 2,p = 0.2),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    transforms.RandomErasing(p=0.2,scale=(0.02, 0.1),value=1.0, inplace=False)\n",
    "])\n",
    "\n",
    "# Convert to TensorDataset and apply transformations\n",
    "class CustomCIFAR10Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "train_dataset = CustomCIFAR10Dataset(train_data, train_labels, transform=transform)\n",
    "\n",
    "# Split into training and validation sets\n",
    "#train_size = int(0.9 * len(train_dataset))\n",
    "#val_size = len(train_dataset) - train_size\n",
    "#train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "batch_test_dict = load_cifar_batch(os.path.join(cifar10_dir, 'test_batch'))\n",
    "val_images = batch_test_dict[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "val_labels = np.array(batch_test_dict[b'labels'])\n",
    "\n",
    "val_dataset = CustomCIFAR10Dataset(val_images, val_labels, transform=test_transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load test dataset\n",
    "cifar_test_path = 'cifar_test_nolabel.pkl'\n",
    "test_batch = load_cifar_batch(cifar_test_path)\n",
    "test_images = test_batch[b'data'].astype(np.float32) / 255.0\n",
    "\n",
    "# Convert test dataset to Tensor\n",
    "test_dataset = [(test_transform(img),) for img in test_images]\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "\n",
    "num_epochs = 100\n",
    "# Train function + plot\n",
    "def train_model(model, train_loader, val_loader, epochs=num_epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[30, 60, 80, 90], gamma=0.1)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100 * correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "    # Plot Losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, epochs + 1), train_losses, label='Train Loss', color='red')\n",
    "    plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss', color='blue')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Train Loss & Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Accuracies\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, epochs + 1), train_accuracies, label='Train Accuracy', color='green')\n",
    "    plt.plot(range(1, epochs + 1), val_accuracies, label='Validation Accuracy', color='purple')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Train Accuracy & Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Define a custom ResNet model from scratch\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.skip = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        identity = x \n",
    "        if self.skip:\n",
    "            identity = self.skip(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.init_bn = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(64, 64, 4, stride=1)\n",
    "        self.layer2 = self._make_layer(64, 128, 4, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, 3, stride=2)\n",
    "        #self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
    "        layers = [ResidualBlock(in_channels, out_channels, stride)]\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.init_conv(x)\n",
    "        out = self.init_bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        #out = self.layer4(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# put models to devices (CPU/GPU)\n",
    "model = CustomResNet().to(device)\n",
    "\n",
    "# Print the number of parameters\n",
    "from torchsummary import summary\n",
    "summary(model, (3, 32, 32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, epochs=num_epochs) #change epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission file\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n",
    "        outputs = model(images) \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Generate submission file\n",
    "submission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\n",
    "submission.to_csv('/kaggle/working/submission1.csv', index=False)\n",
    "print(\"Submission1 file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T19:49:39.342796Z",
     "iopub.status.busy": "2025-03-12T19:49:39.342429Z",
     "iopub.status.idle": "2025-03-12T19:49:39.576292Z",
     "shell.execute_reply": "2025-03-12T19:49:39.574951Z",
     "shell.execute_reply.started": "2025-03-12T19:49:39.342754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# CIFAR-10 class labels\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Get some test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Predict\n",
    "model.eval()\n",
    "outputs = net(images.to(device))\n",
    "_, predicted = outputs.max(1)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = images[i].permute(1, 2, 0).numpy()  # Convert tensor to image\n",
    "    ax.imshow((img * 0.2 + 0.5).clip(0, 1))  # Unnormalize\n",
    "    ax.set_title(f\"Pred: {classes[predicted[i]]}\\nTrue: {classes[labels[i]]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11145869,
     "sourceId": 93057,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "dev3-11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
