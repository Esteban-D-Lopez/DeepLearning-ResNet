{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a560e535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet Architecture Comparisons:\n",
      "   Layers Blocks per Layer             Channels  Parameters\n",
      "0       4     [3, 4, 6, 3]  [64, 128, 256, 512]    21282122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layers</th>\n",
       "      <th>Blocks per Layer</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[3, 4, 6, 3]</td>\n",
       "      <td>[64, 128, 256, 512]</td>\n",
       "      <td>21282122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Layers Blocks per Layer             Channels  Parameters\n",
       "0       4     [3, 4, 6, 3]  [64, 128, 256, 512]    21282122"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return torch.relu(out)\n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, channels, num_classes=10):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.in_planes = channels[0]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, channels[0], kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels[0])\n",
    "        self.layer1 = self._make_layer(block, channels[0], num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, channels[1], num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, channels[2], num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, channels[3], num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(channels[3] * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = torch.nn.functional.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def test_resnet_architectures():\n",
    "    architectures = []\n",
    "    \n",
    "    layer_configs = [\n",
    "        [2, 2],       # 2-layer ResNet\n",
    "        [3, 4, 6],    # 3-layer deeper model\n",
    "        [3, 4, 6, 3], # 4-layer ResNet-34 style\n",
    "    ]\n",
    "    \n",
    "    channel_configs = [\n",
    "        [32, 64],       # Small 2-layer model\n",
    "        [48, 96, 192],  # Balanced 3-layer\n",
    "        [64, 128, 256, 512],  # Full 4-layer ResNet\n",
    "    ]\n",
    "\n",
    "    for layers in layer_configs:\n",
    "        for channels in channel_configs:\n",
    "            try:\n",
    "                model = CustomResNet(BasicBlock, layers, channels)\n",
    "                num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "                \n",
    "                architectures.append({\n",
    "                    \"Layers\": len(layers),\n",
    "                    \"Blocks per Layer\": layers,\n",
    "                    \"Channels\": channels,\n",
    "                    \"Parameters\": num_params\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    df = pd.DataFrame(architectures)\n",
    "    df = df.sort_values(by=\"Parameters\", ascending=True)\n",
    "    return df\n",
    "\n",
    "df_results = test_resnet_architectures()\n",
    "\n",
    "# Display the DataFrame normally\n",
    "print(\"ResNet Architecture Comparisons:\")\n",
    "print(df_results)\n",
    "\n",
    "# Or use Pandas' built-in method in Jupyter\n",
    "from IPython.display import display\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a8f449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet Architecture Comparisons:\n",
      "    Learning Rate  Batch Size  Weight Decay Optimizer          Scheduler\n",
      "0           0.100         128        0.0001       SGD  CosineAnnealingLR\n",
      "1           0.100         128        0.0001       SGD         OneCycleLR\n",
      "2           0.100         128        0.0001     AdamW  CosineAnnealingLR\n",
      "3           0.100         128        0.0001     AdamW         OneCycleLR\n",
      "4           0.100         128        0.0005       SGD  CosineAnnealingLR\n",
      "5           0.100         128        0.0005       SGD         OneCycleLR\n",
      "6           0.100         128        0.0005     AdamW  CosineAnnealingLR\n",
      "7           0.100         128        0.0005     AdamW         OneCycleLR\n",
      "8           0.100         256        0.0001       SGD  CosineAnnealingLR\n",
      "9           0.100         256        0.0001       SGD         OneCycleLR\n",
      "10          0.100         256        0.0001     AdamW  CosineAnnealingLR\n",
      "11          0.100         256        0.0001     AdamW         OneCycleLR\n",
      "12          0.100         256        0.0005       SGD  CosineAnnealingLR\n",
      "13          0.100         256        0.0005       SGD         OneCycleLR\n",
      "14          0.100         256        0.0005     AdamW  CosineAnnealingLR\n",
      "15          0.100         256        0.0005     AdamW         OneCycleLR\n",
      "16          0.010         128        0.0001       SGD  CosineAnnealingLR\n",
      "17          0.010         128        0.0001       SGD         OneCycleLR\n",
      "18          0.010         128        0.0001     AdamW  CosineAnnealingLR\n",
      "19          0.010         128        0.0001     AdamW         OneCycleLR\n",
      "20          0.010         128        0.0005       SGD  CosineAnnealingLR\n",
      "21          0.010         128        0.0005       SGD         OneCycleLR\n",
      "22          0.010         128        0.0005     AdamW  CosineAnnealingLR\n",
      "23          0.010         128        0.0005     AdamW         OneCycleLR\n",
      "24          0.010         256        0.0001       SGD  CosineAnnealingLR\n",
      "25          0.010         256        0.0001       SGD         OneCycleLR\n",
      "26          0.010         256        0.0001     AdamW  CosineAnnealingLR\n",
      "27          0.010         256        0.0001     AdamW         OneCycleLR\n",
      "28          0.010         256        0.0005       SGD  CosineAnnealingLR\n",
      "29          0.010         256        0.0005       SGD         OneCycleLR\n",
      "30          0.010         256        0.0005     AdamW  CosineAnnealingLR\n",
      "31          0.010         256        0.0005     AdamW         OneCycleLR\n",
      "32          0.001         128        0.0001       SGD  CosineAnnealingLR\n",
      "33          0.001         128        0.0001       SGD         OneCycleLR\n",
      "34          0.001         128        0.0001     AdamW  CosineAnnealingLR\n",
      "35          0.001         128        0.0001     AdamW         OneCycleLR\n",
      "36          0.001         128        0.0005       SGD  CosineAnnealingLR\n",
      "37          0.001         128        0.0005       SGD         OneCycleLR\n",
      "38          0.001         128        0.0005     AdamW  CosineAnnealingLR\n",
      "39          0.001         128        0.0005     AdamW         OneCycleLR\n",
      "40          0.001         256        0.0001       SGD  CosineAnnealingLR\n",
      "41          0.001         256        0.0001       SGD         OneCycleLR\n",
      "42          0.001         256        0.0001     AdamW  CosineAnnealingLR\n",
      "43          0.001         256        0.0001     AdamW         OneCycleLR\n",
      "44          0.001         256        0.0005       SGD  CosineAnnealingLR\n",
      "45          0.001         256        0.0005       SGD         OneCycleLR\n",
      "46          0.001         256        0.0005     AdamW  CosineAnnealingLR\n",
      "47          0.001         256        0.0005     AdamW         OneCycleLR\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Weight Decay</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Scheduler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.010</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.010</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.001</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>CosineAnnealingLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.001</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>OneCycleLR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Learning Rate  Batch Size  Weight Decay Optimizer          Scheduler\n",
       "0           0.100         128        0.0001       SGD  CosineAnnealingLR\n",
       "1           0.100         128        0.0001       SGD         OneCycleLR\n",
       "2           0.100         128        0.0001     AdamW  CosineAnnealingLR\n",
       "3           0.100         128        0.0001     AdamW         OneCycleLR\n",
       "4           0.100         128        0.0005       SGD  CosineAnnealingLR\n",
       "5           0.100         128        0.0005       SGD         OneCycleLR\n",
       "6           0.100         128        0.0005     AdamW  CosineAnnealingLR\n",
       "7           0.100         128        0.0005     AdamW         OneCycleLR\n",
       "8           0.100         256        0.0001       SGD  CosineAnnealingLR\n",
       "9           0.100         256        0.0001       SGD         OneCycleLR\n",
       "10          0.100         256        0.0001     AdamW  CosineAnnealingLR\n",
       "11          0.100         256        0.0001     AdamW         OneCycleLR\n",
       "12          0.100         256        0.0005       SGD  CosineAnnealingLR\n",
       "13          0.100         256        0.0005       SGD         OneCycleLR\n",
       "14          0.100         256        0.0005     AdamW  CosineAnnealingLR\n",
       "15          0.100         256        0.0005     AdamW         OneCycleLR\n",
       "16          0.010         128        0.0001       SGD  CosineAnnealingLR\n",
       "17          0.010         128        0.0001       SGD         OneCycleLR\n",
       "18          0.010         128        0.0001     AdamW  CosineAnnealingLR\n",
       "19          0.010         128        0.0001     AdamW         OneCycleLR\n",
       "20          0.010         128        0.0005       SGD  CosineAnnealingLR\n",
       "21          0.010         128        0.0005       SGD         OneCycleLR\n",
       "22          0.010         128        0.0005     AdamW  CosineAnnealingLR\n",
       "23          0.010         128        0.0005     AdamW         OneCycleLR\n",
       "24          0.010         256        0.0001       SGD  CosineAnnealingLR\n",
       "25          0.010         256        0.0001       SGD         OneCycleLR\n",
       "26          0.010         256        0.0001     AdamW  CosineAnnealingLR\n",
       "27          0.010         256        0.0001     AdamW         OneCycleLR\n",
       "28          0.010         256        0.0005       SGD  CosineAnnealingLR\n",
       "29          0.010         256        0.0005       SGD         OneCycleLR\n",
       "30          0.010         256        0.0005     AdamW  CosineAnnealingLR\n",
       "31          0.010         256        0.0005     AdamW         OneCycleLR\n",
       "32          0.001         128        0.0001       SGD  CosineAnnealingLR\n",
       "33          0.001         128        0.0001       SGD         OneCycleLR\n",
       "34          0.001         128        0.0001     AdamW  CosineAnnealingLR\n",
       "35          0.001         128        0.0001     AdamW         OneCycleLR\n",
       "36          0.001         128        0.0005       SGD  CosineAnnealingLR\n",
       "37          0.001         128        0.0005       SGD         OneCycleLR\n",
       "38          0.001         128        0.0005     AdamW  CosineAnnealingLR\n",
       "39          0.001         128        0.0005     AdamW         OneCycleLR\n",
       "40          0.001         256        0.0001       SGD  CosineAnnealingLR\n",
       "41          0.001         256        0.0001       SGD         OneCycleLR\n",
       "42          0.001         256        0.0001     AdamW  CosineAnnealingLR\n",
       "43          0.001         256        0.0001     AdamW         OneCycleLR\n",
       "44          0.001         256        0.0005       SGD  CosineAnnealingLR\n",
       "45          0.001         256        0.0005       SGD         OneCycleLR\n",
       "46          0.001         256        0.0005     AdamW  CosineAnnealingLR\n",
       "47          0.001         256        0.0005     AdamW         OneCycleLR"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "# Define hyperparameter search space\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "batch_sizes = [128, 256]\n",
    "weight_decays = [1e-4, 5e-4]\n",
    "optimizers = ['SGD', 'AdamW']\n",
    "schedulers = ['CosineAnnealingLR', 'OneCycleLR']\n",
    "\n",
    "# Generate all hyperparameter combinations\n",
    "hyperparam_combinations = list(itertools.product(learning_rates, batch_sizes, weight_decays, optimizers, schedulers))\n",
    "\n",
    "hyperparam_results = []\n",
    "\n",
    "for lr, batch_size, wd, optim, sched in hyperparam_combinations:\n",
    "    hyperparam_results.append({\n",
    "        \"Learning Rate\": lr,\n",
    "        \"Batch Size\": batch_size,\n",
    "        \"Weight Decay\": wd,\n",
    "        \"Optimizer\": optim,\n",
    "        \"Scheduler\": sched\n",
    "    })\n",
    "\n",
    "df_hyperparams = pd.DataFrame(hyperparam_results)\n",
    "\n",
    "# Display the DataFrame normally\n",
    "print(\"ResNet Architecture Comparisons:\")\n",
    "print(df_hyperparams)\n",
    "\n",
    "# Or use Pandas' built-in method in Jupyter\n",
    "from IPython.display import display\n",
    "display(df_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f3d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = CustomResNet(BasicBlock, [3, 4, 6], [64, 128, 256]).to(device)  # Adjust based on the best model\n",
    "model_path = \"optimized_model.pth\"  # Local model path\n",
    "\n",
    "# Load weights\n",
    "net.load_state_dict(torch.load(model_path, map_location=device))\n",
    "net.eval()\n",
    "\n",
    "# Run inference on local test data\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images, indices in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        for idx, label in zip(indices.numpy(), predicted.cpu().numpy()):\n",
    "            predictions.append((idx, label))\n",
    "\n",
    "# Save local submission file\n",
    "submission_df = pd.DataFrame(predictions, columns=[\"ID\", \"Label\"])\n",
    "submission_file = \"submission.csv\"\n",
    "submission_df.to_csv(submission_file, index=False)\n",
    "print(f\"Local Submission file saved: {submission_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
